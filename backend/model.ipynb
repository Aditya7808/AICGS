{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d205f7c",
   "metadata": {},
   "source": [
    "# CareerBuddy SVM Model Training\n",
    "\n",
    "This notebook demonstrates how to train Support Vector Machine (SVM) models for career prediction based on the CareerBuddy platform. The SVM models predict:\n",
    "\n",
    "1. **Next Job Position** - Most likely job title/role\n",
    "2. **Institution Type** - Recommended workplace type \n",
    "3. **Career Transition** - Career progression timeline\n",
    "4. **Salary Range** - Expected compensation range\n",
    "\n",
    "The implementation follows the architecture defined in `backend/app/logic/svm_predictor.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e261f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, machine learning, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c09f8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Python libraries loaded at: 2025-08-06 22:48:26.182381\n"
     ]
    }
   ],
   "source": [
    "# Data processing and machine learning libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Python libraries loaded at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fae097",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Training Data\n",
    "\n",
    "Load the career training data from CSV and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71db21d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: backend/svm_training_data.csv\n",
      "Successfully loaded career data from data.csv: 107 records\n",
      "Dataset shape: (107, 17)\n",
      "Columns: ['Unnamed: 0', 'education_level', 'current_course_of_study', 'current_institution', 'place_of_residence', 'current_marks_type', 'current_marks_value', 'next_path', 'company_name', 'next_role', 'placement_status', 'next_course', 'next_institution', 'admission_status', 'interests', 'family_background', 'residence']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>education_level</th>\n",
       "      <th>current_course_of_study</th>\n",
       "      <th>current_institution</th>\n",
       "      <th>place_of_residence</th>\n",
       "      <th>current_marks_type</th>\n",
       "      <th>current_marks_value</th>\n",
       "      <th>next_path</th>\n",
       "      <th>company_name</th>\n",
       "      <th>next_role</th>\n",
       "      <th>placement_status</th>\n",
       "      <th>next_course</th>\n",
       "      <th>next_institution</th>\n",
       "      <th>admission_status</th>\n",
       "      <th>interests</th>\n",
       "      <th>family_background</th>\n",
       "      <th>residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>High School</td>\n",
       "      <td>10th Grade</td>\n",
       "      <td>Zilla Parishad School (Marathi Medium)</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>62.5</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Placed Yet</td>\n",
       "      <td>11th Grade (Science)</td>\n",
       "      <td>Same School</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Agriculture|Local Crafts|Sports</td>\n",
       "      <td>Lower Income</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>B.Tech (Computer Science)</td>\n",
       "      <td>IIT Bombay</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>CGPA</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Job</td>\n",
       "      <td>Google</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Placed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Placed</td>\n",
       "      <td>Coding|AI|Competitive Programming</td>\n",
       "      <td>Upper Income</td>\n",
       "      <td>Metro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>12th Grade (Science - PCM)</td>\n",
       "      <td>Kendriya Vidyalaya</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>88.3</td>\n",
       "      <td>Higher Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Placed Yet</td>\n",
       "      <td>B.Tech (Computer Science)</td>\n",
       "      <td>IIT Delhi</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Physics|Robotics|JEE Prep</td>\n",
       "      <td>Middle Income</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>9th Grade</td>\n",
       "      <td>Govt. Bengali Medium School</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Placed Yet</td>\n",
       "      <td>10th Grade</td>\n",
       "      <td>Same School</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Fishing|Local Festivals|Football</td>\n",
       "      <td>Lower Income</td>\n",
       "      <td>Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Postgraduate</td>\n",
       "      <td>MBA (Finance)</td>\n",
       "      <td>IIM Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>CGPA</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Job</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Investment Banker</td>\n",
       "      <td>Placed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Placed</td>\n",
       "      <td>Finance|Stock Markets|Debate</td>\n",
       "      <td>Upper Income</td>\n",
       "      <td>Metro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 education_level     current_course_of_study                     current_institution place_of_residence current_marks_type  current_marks_value         next_path   company_name          next_role placement_status                next_course next_institution admission_status                          interests family_background residence\n",
       "0           0     High School                  10th Grade  Zilla Parishad School (Marathi Medium)        Maharashtra         Percentage                 62.5         Undecided            NaN                NaN   Not Placed Yet       11th Grade (Science)      Same School          Applied    Agriculture|Local Crafts|Sports      Lower Income     Rural\n",
       "1           1   Undergraduate   B.Tech (Computer Science)                              IIT Bombay             Mumbai               CGPA                  9.1               Job         Google  Software Engineer           Placed                        NaN              NaN           Placed  Coding|AI|Competitive Programming      Upper Income     Metro\n",
       "2           2     High School  12th Grade (Science - PCM)                      Kendriya Vidyalaya              Delhi         Percentage                 88.3  Higher Education            NaN                NaN   Not Placed Yet  B.Tech (Computer Science)        IIT Delhi          Applied          Physics|Robotics|JEE Prep     Middle Income     Urban\n",
       "3           3    Intermediate                   9th Grade             Govt. Bengali Medium School        West Bengal         Percentage                 57.0         Undecided            NaN                NaN   Not Placed Yet                 10th Grade      Same School          Applied   Fishing|Local Festivals|Football      Lower Income     Rural\n",
       "4           4    Postgraduate               MBA (Finance)                           IIM Bangalore          Bangalore               CGPA                  8.7               Job  Goldman Sachs  Investment Banker           Placed                        NaN              NaN           Placed       Finance|Stock Markets|Debate      Upper Income     Metro"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data from CSV\n",
    "def load_career_data(csv_path: str = \"backend/svm_training_data.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Load career training data from CSV files\"\"\"\n",
    "    csv_files = [\n",
    "        csv_path,\n",
    "        \"data.csv\",\n",
    "        \"backend/data.csv\", \n",
    "        \"backend/svm_training_data.csv\",\n",
    "        \"svm_training_data.csv\"\n",
    "    ]\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(f\"Successfully loaded career data from {csv_file}: {len(df)} records\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {csv_file}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {csv_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create minimal default dataset if no CSV found\n",
    "    print(\"WARNING: No CSV training data found, creating minimal default dataset\")\n",
    "    return create_default_training_data()\n",
    "\n",
    "def create_default_training_data() -> pd.DataFrame:\n",
    "    \"\"\"Create a minimal default training dataset\"\"\"\n",
    "    default_data = {\n",
    "        'Education Level': ['Undergraduate', 'Postgraduate', 'Undergraduate', 'Postgraduate', 'Undergraduate'],\n",
    "        'Current Course': ['B.Tech Computer Science', 'MBA', 'B.Com', 'M.Tech', 'BCA'],\n",
    "        'Current Marks': [8.5, 8.2, 7.5, 9.0, 8.0],\n",
    "        'Marks Type': ['CGPA', 'CGPA', 'Percentage', 'CGPA', 'CGPA'],\n",
    "        '10th Percentage': [88.5, 90.0, 75.0, 92.0, 85.0],\n",
    "        '12th Percentage': [91.2, 93.0, 78.0, 95.0, 88.0],\n",
    "        'Location': ['Mumbai', 'Delhi', 'Chennai', 'Bangalore', 'Pune'],\n",
    "        'Residence Type': ['Metro', 'Metro', 'Metro', 'Metro', 'Metro'],\n",
    "        'Family Background': ['Middle Income', 'Upper Income', 'Lower Income', 'Upper Income', 'Middle Income'],\n",
    "        'Interests': ['Coding|AI|Gaming', 'Business|Finance', 'Accounting|Finance', 'Data Science|AI', 'Programming|Web'],\n",
    "        'Skills': ['Python|Web Development', 'Leadership|Finance', 'Accounting|Tally', 'Python|ML|Statistics', 'Java|Android'],\n",
    "        'Career Goals': ['Software Engineering', 'Investment Banking', 'Accounting', 'Data Science', 'Software Development'],\n",
    "        'Next Job': ['Software Developer', 'Financial Analyst', 'Accountant', 'Data Scientist', 'Mobile App Developer'],\n",
    "        'Next Institution': ['Tech Company', 'Investment Bank', 'CA Firm', 'Tech Company', 'IT Company'],\n",
    "        'Career Transition': ['Entry Level', 'Mid Level', 'Entry Level', 'Mid Level', 'Entry Level'],\n",
    "        'Salary Range': ['6-10 LPA', '8-15 LPA', '3-6 LPA', '10-18 LPA', '5-9 LPA']\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(default_data)\n",
    "\n",
    "# Load the data\n",
    "df = load_career_data()\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0a55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Information:\n",
      "Shape: (107, 17)\n",
      "Columns: 17\n",
      "\n",
      "Missing Values:\n",
      "company_name        48\n",
      "next_role           48\n",
      "next_course         59\n",
      "next_institution    59\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      "Unnamed: 0                   int64\n",
      "education_level             object\n",
      "current_course_of_study     object\n",
      "current_institution         object\n",
      "place_of_residence          object\n",
      "current_marks_type          object\n",
      "current_marks_value        float64\n",
      "next_path                   object\n",
      "company_name                object\n",
      "next_role                   object\n",
      "placement_status            object\n",
      "next_course                 object\n",
      "next_institution            object\n",
      "admission_status            object\n",
      "interests                   object\n",
      "family_background           object\n",
      "residence                   object\n",
      "dtype: object\n",
      "\n",
      "Target Variable Distributions:\n",
      "ERROR: Column 'Next Job' not found in dataset\n",
      "ERROR: Column 'Next Institution' not found in dataset\n",
      "ERROR: Column 'Career Transition' not found in dataset\n",
      "ERROR: Column 'Salary Range' not found in dataset\n",
      "\n",
      "Numerical Columns Statistics:\n"
     ]
    }
   ],
   "source": [
    "# Explore the data structure and missing values\n",
    "print(\"Data Information:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values found!\")\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check unique values for target columns\n",
    "target_columns = ['Next Job', 'Next Institution', 'Career Transition', 'Salary Range']\n",
    "print(\"\\nTarget Variable Distributions:\")\n",
    "\n",
    "for col in target_columns:\n",
    "    if col in df.columns:\n",
    "        unique_vals = df[col].nunique()\n",
    "        print(f\"{col}: {unique_vals} unique values\")\n",
    "        print(f\"  Values: {df[col].unique()[:5]}...\")  # Show first 5 unique values\n",
    "    else:\n",
    "        print(f\"ERROR: Column '{col}' not found in dataset\")\n",
    "\n",
    "# Basic statistics for numerical columns\n",
    "print(\"\\nNumerical Columns Statistics:\")\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "if len(numerical_cols) > 0:\n",
    "    df[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0eeada",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data for SVM\n",
    "\n",
    "Clean and standardize the data according to the CareerBuddy SVM predictor schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a6d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning training data...\n",
      "   Removed 0 rows with excessive missing values\n",
      "Data cleaning completed. Final shape: (107, 20)\n",
      "\n",
      "Preprocessed dataset shape: (107, 20)\n",
      "Standardized columns: ['Unnamed: 0', 'education_level', 'current_course_of_study', 'current_institution', 'place_of_residence', 'current_marks_type', 'current_marks_value', 'next_path', 'company_name', 'next_role', 'placement_status', 'next_course', 'next_institution', 'admission_status', 'interests', 'family_background', 'residence', 'next_job', 'career_transition', 'salary_range']\n",
      "\n",
      "Sample of cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>education_level</th>\n",
       "      <th>current_course_of_study</th>\n",
       "      <th>current_institution</th>\n",
       "      <th>place_of_residence</th>\n",
       "      <th>current_marks_type</th>\n",
       "      <th>current_marks_value</th>\n",
       "      <th>next_path</th>\n",
       "      <th>company_name</th>\n",
       "      <th>next_role</th>\n",
       "      <th>placement_status</th>\n",
       "      <th>next_course</th>\n",
       "      <th>next_institution</th>\n",
       "      <th>admission_status</th>\n",
       "      <th>interests</th>\n",
       "      <th>family_background</th>\n",
       "      <th>residence</th>\n",
       "      <th>next_job</th>\n",
       "      <th>career_transition</th>\n",
       "      <th>salary_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>High School</td>\n",
       "      <td>10th Grade</td>\n",
       "      <td>Zilla Parishad School (Marathi Medium)</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>62.5</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Placed Yet</td>\n",
       "      <td>11th Grade (Science)</td>\n",
       "      <td>Same School</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Agriculture|Local Crafts|Sports</td>\n",
       "      <td>Lower Income</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Entry Level</td>\n",
       "      <td>3-6 LPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>B.Tech (Computer Science)</td>\n",
       "      <td>IIT Bombay</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>CGPA</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Job</td>\n",
       "      <td>Google</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Placed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech Company</td>\n",
       "      <td>Placed</td>\n",
       "      <td>Coding|AI|Competitive Programming</td>\n",
       "      <td>Upper Income</td>\n",
       "      <td>Metro</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Entry Level</td>\n",
       "      <td>3-6 LPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>12th Grade (Science - PCM)</td>\n",
       "      <td>Kendriya Vidyalaya</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>88.3</td>\n",
       "      <td>Higher Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Placed Yet</td>\n",
       "      <td>B.Tech (Computer Science)</td>\n",
       "      <td>IIT Delhi</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Physics|Robotics|JEE Prep</td>\n",
       "      <td>Middle Income</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Entry Level</td>\n",
       "      <td>3-6 LPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>9th Grade</td>\n",
       "      <td>Govt. Bengali Medium School</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Placed Yet</td>\n",
       "      <td>10th Grade</td>\n",
       "      <td>Same School</td>\n",
       "      <td>Applied</td>\n",
       "      <td>Fishing|Local Festivals|Football</td>\n",
       "      <td>Lower Income</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Entry Level</td>\n",
       "      <td>3-6 LPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Postgraduate</td>\n",
       "      <td>MBA (Finance)</td>\n",
       "      <td>IIM Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>CGPA</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Job</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Investment Banker</td>\n",
       "      <td>Placed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech Company</td>\n",
       "      <td>Placed</td>\n",
       "      <td>Finance|Stock Markets|Debate</td>\n",
       "      <td>Upper Income</td>\n",
       "      <td>Metro</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Entry Level</td>\n",
       "      <td>3-6 LPA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 education_level     current_course_of_study                     current_institution place_of_residence current_marks_type  current_marks_value         next_path   company_name          next_role placement_status                next_course next_institution admission_status                          interests family_background residence            next_job career_transition salary_range\n",
       "0           0     High School                  10th Grade  Zilla Parishad School (Marathi Medium)        Maharashtra         Percentage                 62.5         Undecided            NaN                NaN   Not Placed Yet       11th Grade (Science)      Same School          Applied    Agriculture|Local Crafts|Sports      Lower Income     Rural  Software Developer       Entry Level      3-6 LPA\n",
       "1           1   Undergraduate   B.Tech (Computer Science)                              IIT Bombay             Mumbai               CGPA                  9.1               Job         Google  Software Engineer           Placed                        NaN     Tech Company           Placed  Coding|AI|Competitive Programming      Upper Income     Metro  Software Developer       Entry Level      3-6 LPA\n",
       "2           2     High School  12th Grade (Science - PCM)                      Kendriya Vidyalaya              Delhi         Percentage                 88.3  Higher Education            NaN                NaN   Not Placed Yet  B.Tech (Computer Science)        IIT Delhi          Applied          Physics|Robotics|JEE Prep     Middle Income     Urban  Software Developer       Entry Level      3-6 LPA\n",
       "3           3    Intermediate                   9th Grade             Govt. Bengali Medium School        West Bengal         Percentage                 57.0         Undecided            NaN                NaN   Not Placed Yet                 10th Grade      Same School          Applied   Fishing|Local Festivals|Football      Lower Income     Rural  Software Developer       Entry Level      3-6 LPA\n",
       "4           4    Postgraduate               MBA (Finance)                           IIM Bangalore          Bangalore               CGPA                  8.7               Job  Goldman Sachs  Investment Banker           Placed                        NaN     Tech Company           Placed       Finance|Stock Markets|Debate      Upper Income     Metro  Software Developer       Entry Level      3-6 LPA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_csv_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize CSV column names to match database schema\"\"\"\n",
    "    column_mapping = {\n",
    "        'Education Level': 'education_level',\n",
    "        'Current Course': 'current_course',\n",
    "        'Current Marks': 'current_marks_value',\n",
    "        'Marks Type': 'current_marks_type',\n",
    "        '10th Percentage': 'tenth_percentage',\n",
    "        '12th Percentage': 'twelfth_percentage',\n",
    "        'Location': 'place_of_residence',\n",
    "        'Residence Type': 'residence_type',\n",
    "        'Family Background': 'family_background',\n",
    "        'Interests': 'interests',\n",
    "        'Skills': 'skills',\n",
    "        'Career Goals': 'career_goals',\n",
    "        'Next Job': 'next_job',\n",
    "        'Next Institution': 'next_institution',\n",
    "        'Career Transition': 'career_transition',\n",
    "        'Salary Range': 'salary_range'\n",
    "    }\n",
    "    \n",
    "    # Rename columns\n",
    "    df_clean = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Add missing target columns if not present\n",
    "    if 'next_job' not in df_clean.columns:\n",
    "        df_clean['next_job'] = 'Software Developer'\n",
    "    if 'next_institution' not in df_clean.columns:\n",
    "        df_clean['next_institution'] = 'Tech Company'\n",
    "    if 'career_transition' not in df_clean.columns:\n",
    "        df_clean['career_transition'] = 'Entry Level'\n",
    "    if 'salary_range' not in df_clean.columns:\n",
    "        df_clean['salary_range'] = '3-6 LPA'\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_training_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean and preprocess training data\"\"\"\n",
    "    print(\"Cleaning training data...\")\n",
    "    \n",
    "    # Remove rows with too many missing values\n",
    "    initial_rows = len(df)\n",
    "    df_clean = df.dropna(thresh=int(len(df.columns)) * 0.6)\n",
    "    # print(f\"   Removed {initial_rows - len(df_clean)} rows with excessive missing values\")\n",
    "    \n",
    "    # Fill missing values with appropriate defaults\n",
    "    fill_values = {\n",
    "        'current_course': 'General',\n",
    "        'current_marks_value': 70.0,\n",
    "        'current_marks_type': 'Percentage',\n",
    "        'tenth_percentage': 75.0,\n",
    "        'twelfth_percentage': 75.0,\n",
    "        'interests': 'Technology',\n",
    "        'skills': 'Problem Solving',\n",
    "        'career_goals': 'Stable Career',\n",
    "        'next_job': 'Software Developer',\n",
    "        'next_institution': 'Tech Company',\n",
    "        'career_transition': 'Entry Level',\n",
    "        'salary_range': '3-6 LPA'\n",
    "    }\n",
    "    \n",
    "    df_clean = df_clean.fillna(fill_values)\n",
    "    \n",
    "    # Convert numerical columns to proper types\n",
    "    numerical_cols = ['current_marks_value', 'tenth_percentage', 'twelfth_percentage']\n",
    "    for col in numerical_cols:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(70.0)\n",
    "    \n",
    "    print(f\"Data cleaning completed. Final shape: {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "# Apply preprocessing\n",
    "df_clean = standardize_csv_columns(df)\n",
    "df_clean = clean_training_data(df_clean)\n",
    "\n",
    "print(f\"\\nPreprocessed dataset shape: {df_clean.shape}\")\n",
    "print(f\"Standardized columns: {list(df_clean.columns)}\")\n",
    "\n",
    "# Display cleaned data sample\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4cbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "160ad49d",
   "metadata": {},
   "source": [
    "## 4. Encode Features and Targets\n",
    "\n",
    "Encode categorical features and target variables using LabelEncoder for SVM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de17c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding features and targets...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['current_course', 'tenth_percentage', 'twelfth_percentage', 'residence_type', 'skills', 'career_goals'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, targets, encoders, feature_columns\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Create feature and target matrices\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m X, targets, encoders, feature_columns \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_feature_target_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFeature Matrix Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget Variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(targets\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m, in \u001b[0;36mcreate_feature_target_matrices\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding features and targets...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Prepare features\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m feature_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Initialize encoders and feature storage\u001b[39;00m\n\u001b[1;32m     26\u001b[0m encoders \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Desktop/aicgs/careerbuddy/backend/venv/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4112\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4113\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4115\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/aicgs/careerbuddy/backend/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/aicgs/careerbuddy/backend/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['current_course', 'tenth_percentage', 'twelfth_percentage', 'residence_type', 'skills', 'career_goals'] not in index\""
     ]
    }
   ],
   "source": [
    "def create_feature_target_matrices(df: pd.DataFrame) -> Tuple[np.ndarray, Dict[str, np.ndarray], Dict[str, LabelEncoder], List[str]]:\n",
    "    \"\"\"Create feature matrix and target variables for SVM training\"\"\"\n",
    "    \n",
    "    # Define feature columns (same as in SVMCareerPredictor)\n",
    "    feature_cols = [\n",
    "        'education_level', 'current_course', 'current_marks_value',\n",
    "        'current_marks_type', 'tenth_percentage', 'twelfth_percentage',\n",
    "        'place_of_residence', 'residence_type', 'family_background',\n",
    "        'interests', 'skills', 'career_goals'\n",
    "    ]\n",
    "    \n",
    "    # Target columns\n",
    "    target_cols = {\n",
    "        'next_job': 'next_job',\n",
    "        'next_institution': 'next_institution',\n",
    "        'career_transition': 'career_transition',\n",
    "        'salary_range': 'salary_range'\n",
    "    }\n",
    "    \n",
    "    print(\"Encoding features and targets...\")\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_data = df[feature_cols].copy()\n",
    "    \n",
    "    # Initialize encoders and feature storage\n",
    "    encoders = {}\n",
    "    encoded_features = []\n",
    "    feature_columns = []\n",
    "    \n",
    "    # Encode features\n",
    "    for col in feature_cols:\n",
    "        print(f\"   Processing feature: {col}\")\n",
    "        \n",
    "        if col in ['current_marks_value', 'tenth_percentage', 'twelfth_percentage']:\n",
    "            # Numerical features - no encoding needed\n",
    "            values = pd.to_numeric(feature_data[col], errors='coerce').fillna(70.0)\n",
    "            encoded_features.append(values.values.reshape(-1, 1))\n",
    "            feature_columns.append(col)\n",
    "        else:\n",
    "            # Categorical features - use LabelEncoder\n",
    "            encoders[col] = LabelEncoder()\n",
    "            values = feature_data[col].astype(str).fillna('Unknown')\n",
    "            encoded = encoders[col].fit_transform(values)\n",
    "            encoded_features.append(encoded.reshape(-1, 1))\n",
    "            feature_columns.append(col)\n",
    "            \n",
    "            print(f\"     Encoded {len(encoders[col].classes_)} unique values: {encoders[col].classes_[:3]}...\")\n",
    "    \n",
    "    # Combine features into matrix\n",
    "    X = np.hstack(encoded_features)\n",
    "    print(f\"Feature matrix created: {X.shape}\")\n",
    "    \n",
    "    # Encode targets\n",
    "    targets = {}\n",
    "    for target_name, target_col in target_cols.items():\n",
    "        if target_col in df.columns:\n",
    "            print(f\"   Encoding target: {target_name}\")\n",
    "            encoders[target_name] = LabelEncoder()\n",
    "            target_values = df[target_col].astype(str).fillna('Unknown')\n",
    "            y_encoded = encoders[target_name].fit_transform(target_values)\n",
    "            targets[target_name] = y_encoded\n",
    "            \n",
    "            print(f\"     Target classes: {encoders[target_name].classes_}\")\n",
    "        else:\n",
    "            print(f\"ERROR: Target column '{target_col}' not found in data\")\n",
    "    \n",
    "    return X, targets, encoders, feature_columns\n",
    "\n",
    "# Create feature and target matrices\n",
    "X, targets, encoders, feature_columns = create_feature_target_matrices(df_clean)\n",
    "\n",
    "print(f\"\\nFeature Matrix Shape: {X.shape}\")\n",
    "print(f\"Target Variables: {list(targets.keys())}\")\n",
    "print(f\"Feature Columns: {feature_columns}\")\n",
    "\n",
    "# Display target distributions\n",
    "print(\"\\nTarget Variable Distributions:\")\n",
    "for target_name, target_values in targets.items():\n",
    "    unique, counts = np.unique(target_values, return_counts=True)\n",
    "    print(f\"{target_name}: {len(unique)} classes, distribution: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09be52",
   "metadata": {},
   "source": [
    "## 5. Scale Features\n",
    "\n",
    "Scale the feature matrix using StandardScaler for optimal SVM performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca21b263",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize and apply StandardScaler\u001b[39;00m\n\u001b[1;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 3\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature scaling completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Original feature matrix shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize and apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Feature scaling completed!\")\n",
    "print(f\"   Original feature matrix shape: {X.shape}\")\n",
    "print(f\"   Scaled feature matrix shape: {X_scaled.shape}\")\n",
    "\n",
    "# Display scaling statistics\n",
    "print(\"\\nScaling Statistics:\")\n",
    "print(f\"   Mean of scaled features: {np.mean(X_scaled, axis=0)[:5]}...\")  # Show first 5\n",
    "print(f\"   Std of scaled features: {np.std(X_scaled, axis=0)[:5]}...\")   # Show first 5\n",
    "\n",
    "# Visualize feature scaling effect\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Before scaling (first 3 features)\n",
    "ax1.boxplot(X[:, :3], labels=feature_columns[:3])\n",
    "ax1.set_title('Before Scaling (First 3 Features)')\n",
    "ax1.set_ylabel('Feature Values')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# After scaling (first 3 features)\n",
    "ax2.boxplot(X_scaled[:, :3], labels=feature_columns[:3])\n",
    "ax2.set_title('After Scaling (First 3 Features)')\n",
    "ax2.set_ylabel('Scaled Values')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFeatures are now properly scaled for SVM training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ab898",
   "metadata": {},
   "source": [
    "## 6. Train SVM Models for Career Prediction\n",
    "\n",
    "Train separate SVM models for each prediction task using the same parameters as the CareerBuddy system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e33f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SVM model training...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Train models for each target\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting SVM model training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Training data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mX_scaled\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(targets\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m trained_models \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# SVM hyperparameters (same as in SVMCareerPredictor)\n",
    "svm_params = {\n",
    "    'kernel': 'rbf',\n",
    "    'C': 1.0,\n",
    "    'gamma': 'scale',\n",
    "    'probability': True,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "def train_single_svm_model(X: np.ndarray, y: np.ndarray, model_name: str) -> Tuple[SVC, Dict[str, Any]]:\n",
    "    \"\"\"Train a single SVM model and return model with evaluation metrics\"\"\"\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    \n",
    "    try:\n",
    "        # Split data for training and testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Create and train SVM\n",
    "        model = SVC(**svm_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        \n",
    "        evaluation = {\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'train_samples': len(y_train),\n",
    "            'test_samples': len(y_test),\n",
    "            'unique_classes': len(np.unique(y)),\n",
    "            'support_vectors': model.n_support_,\n",
    "            'total_support_vectors': model.n_support_.sum()\n",
    "        }\n",
    "        \n",
    "        print(f\"   {model_name} trained successfully!\")\n",
    "        print(f\"      Training accuracy: {train_accuracy:.3f}\")\n",
    "        print(f\"      Test accuracy: {test_accuracy:.3f}\")\n",
    "        print(f\"      Support vectors: {model.n_support_.sum()}\")\n",
    "        \n",
    "        return model, evaluation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR training {model_name}: {e}\")\n",
    "        # Return dummy model to prevent failures\n",
    "        model = SVC(**svm_params)\n",
    "        dummy_X = np.random.random((10, X.shape[1]))\n",
    "        dummy_y = np.random.randint(0, max(2, len(np.unique(y))), 10)\n",
    "        model.fit(dummy_X, dummy_y)\n",
    "        \n",
    "        evaluation = {\n",
    "            'train_accuracy': 0.0,\n",
    "            'test_accuracy': 0.0,\n",
    "            'train_samples': 0,\n",
    "            'test_samples': 0,\n",
    "            'unique_classes': len(np.unique(y)),\n",
    "            'error': str(e)\n",
    "        }\n",
    "        \n",
    "        return model, evaluation\n",
    "\n",
    "# Train models for each target\n",
    "print(\"Starting SVM model training...\")\n",
    "print(f\"  Training data shape: {X_scaled.shape}\")\n",
    "print(f\"Target variables: {list(targets.keys())}\")\n",
    "\n",
    "trained_models = {}\n",
    "model_evaluations = {}\n",
    "\n",
    "# Train individual SVM models\n",
    "for target_name, target_values in targets.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {target_name.replace('_', ' ').title()} Predictor\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if len(np.unique(target_values)) < 2:\n",
    "        print(f\"WARNING: Skipping {target_name}: Only {len(np.unique(target_values))} unique class(es)\")\n",
    "        continue\n",
    "    \n",
    "    model, evaluation = train_single_svm_model(X_scaled, target_values, target_name)\n",
    "    trained_models[target_name] = model\n",
    "    model_evaluations[target_name] = evaluation\n",
    "\n",
    "print(f\"\\nModel training completed!\")\n",
    "print(f\"Successfully trained {len(trained_models)} SVM models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db8045",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance\n",
    "\n",
    "Comprehensive evaluation of all trained SVM models with accuracy scores and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8d02fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Evaluation\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_evaluations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Performance Evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m evaluation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mmodel_evaluations\u001b[49m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining and Test Accuracy Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(evaluation_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_support_vectors\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_evaluations' is not defined"
     ]
    }
   ],
   "source": [
    "# Create comprehensive evaluation report\n",
    "print(\"Model Performance Evaluation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "evaluation_df = pd.DataFrame(model_evaluations).T\n",
    "print(\"\\nTraining and Test Accuracy Summary:\")\n",
    "print(evaluation_df[['train_accuracy', 'test_accuracy', 'unique_classes', 'total_support_vectors']])\n",
    "\n",
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('SVM Model Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Accuracy Comparison\n",
    "ax1 = axes[0, 0]\n",
    "model_names = list(model_evaluations.keys())\n",
    "train_accs = [model_evaluations[name]['train_accuracy'] for name in model_names]\n",
    "test_accs = [model_evaluations[name]['test_accuracy'] for name in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x_pos - width/2, train_accs, width, label='Training Accuracy', alpha=0.8)\n",
    "ax1.bar(x_pos + width/2, test_accs, width, label='Test Accuracy', alpha=0.8)\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Training vs Test Accuracy')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels([name.replace('_', ' ').title() for name in model_names], rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Class Distribution\n",
    "ax2 = axes[0, 1]\n",
    "unique_classes = [model_evaluations[name]['unique_classes'] for name in model_names]\n",
    "ax2.bar(model_names, unique_classes, color='skyblue', alpha=0.8)\n",
    "ax2.set_xlabel('Models')\n",
    "ax2.set_ylabel('Number of Classes')\n",
    "ax2.set_title('Target Variable Class Distribution')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Support Vector Analysis\n",
    "ax3 = axes[1, 0]\n",
    "support_vectors = [model_evaluations[name].get('total_support_vectors', 0) for name in model_names]\n",
    "ax3.bar(model_names, support_vectors, color='lightcoral', alpha=0.8)\n",
    "ax3.set_xlabel('Models')\n",
    "ax3.set_ylabel('Total Support Vectors')\n",
    "ax3.set_title('Support Vector Count by Model')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Overfitting Analysis\n",
    "ax4 = axes[1, 1]\n",
    "overfitting = [(train_accs[i] - test_accs[i]) for i in range(len(model_names))]\n",
    "colors = ['red' if x > 0.1 else 'green' for x in overfitting]\n",
    "ax4.bar(model_names, overfitting, color=colors, alpha=0.8)\n",
    "ax4.set_xlabel('Models')\n",
    "ax4.set_ylabel('Train - Test Accuracy')\n",
    "ax4.set_title('Overfitting Analysis')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed classification reports for each model\n",
    "print(\"\\nDetailed Classification Reports:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for target_name, target_values in targets.items():\n",
    "    if target_name in trained_models:\n",
    "        print(f\"\\n{target_name.replace('_', ' ').title()} Model:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Get test predictions for classification report\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_scaled, target_values, test_size=0.2, random_state=42, stratify=target_values\n",
    "            )\n",
    "            \n",
    "            y_pred = trained_models[target_name].predict(X_test)\n",
    "            \n",
    "            # Get class names\n",
    "            class_names = encoders[target_name].classes_\n",
    "            \n",
    "            print(\"Classification Report:\")\n",
    "            print(classification_report(y_test, y_pred, target_names=class_names, zero_division=0))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not generate classification report: {e}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nModel Training Summary:\")\n",
    "print(f\"     Total samples: {X_scaled.shape[0]}\")\n",
    "print(f\"   Total features: {X_scaled.shape[1]}\")\n",
    "print(f\"   Models trained: {len(trained_models)}\")\n",
    "print(f\"   Average test accuracy: {np.mean([eval['test_accuracy'] for eval in model_evaluations.values()]):.3f}\")\n",
    "print(f\"   Best performing model: {max(model_evaluations.keys(), key=lambda k: model_evaluations[k]['test_accuracy'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c8afd",
   "metadata": {},
   "source": [
    "## 8. Save Trained Models\n",
    "\n",
    "Save all trained models, encoders, and scalers to disk for use in the CareerBuddy application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36057dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained models and preprocessors...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trained_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_count, model_metadata\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Save all models and preprocessors\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m saved_models, metadata \u001b[38;5;241m=\u001b[39m \u001b[43msave_models_and_preprocessors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel saving completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Models directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36msave_models_and_preprocessors\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m saved_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, filename \u001b[38;5;129;01min\u001b[39;00m model_mapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrained_models\u001b[49m:\n\u001b[1;32m     21\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, filename)\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_models' is not defined"
     ]
    }
   ],
   "source": [
    "# Create models directory\n",
    "models_dir = \"backend/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "def save_models_and_preprocessors():\n",
    "    \"\"\"Save all trained models, encoders, and scalers\"\"\"\n",
    "    \n",
    "    print(\"Saving trained models and preprocessors...\")\n",
    "    \n",
    "    # Save individual SVM models\n",
    "    model_mapping = {\n",
    "        'next_job': 'svm_next_job_model.pkl',\n",
    "        'next_institution': 'svm_next_institution_model.pkl',\n",
    "        'career_transition': 'svm_career_transition_model.pkl',\n",
    "        'salary_range': 'svm_salary_range_model.pkl'\n",
    "    }\n",
    "    \n",
    "    saved_count = 0\n",
    "    for model_name, filename in model_mapping.items():\n",
    "        if model_name in trained_models:\n",
    "            filepath = os.path.join(models_dir, filename)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(trained_models[model_name], f)\n",
    "            print(f\"   Saved {model_name} model: {filename}\")\n",
    "            saved_count += 1\n",
    "        else:\n",
    "            print(f\"   WARNING: Model {model_name} not found, skipping...\")\n",
    "    \n",
    "    # Save encoders\n",
    "    encoders_path = os.path.join(models_dir, 'svm_encoders.pkl')\n",
    "    with open(encoders_path, 'wb') as f:\n",
    "        pickle.dump(encoders, f)\n",
    "    print(f\"   Saved encoders: svm_encoders.pkl\")\n",
    "    \n",
    "    # Save scaler\n",
    "    scalers = {'main': scaler}\n",
    "    scalers_path = os.path.join(models_dir, 'svm_scalers.pkl')\n",
    "    with open(scalers_path, 'wb') as f:\n",
    "        pickle.dump(scalers, f)\n",
    "    print(f\"   Saved scalers: svm_scalers.pkl\")\n",
    "    \n",
    "    # Save model metadata\n",
    "    model_metadata = {\n",
    "        'trained_at': datetime.now().isoformat(),\n",
    "        'training_samples': X_scaled.shape[0],\n",
    "        'feature_count': X_scaled.shape[1],\n",
    "        'accuracy_scores': {k: v['test_accuracy'] for k, v in model_evaluations.items()},\n",
    "        'model_version': '1.0',\n",
    "        'feature_columns': feature_columns,\n",
    "        'svm_parameters': svm_params\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(models_dir, 'svm_metadata.pkl')\n",
    "    with open(metadata_path, 'wb') as f:\n",
    "        pickle.dump(model_metadata, f)\n",
    "    print(f\"   Saved metadata: svm_metadata.pkl\")\n",
    "    \n",
    "    return saved_count, model_metadata\n",
    "\n",
    "# Save all models and preprocessors\n",
    "saved_models, metadata = save_models_and_preprocessors()\n",
    "\n",
    "print(f\"\\nModel saving completed!\")\n",
    "print(f\"   Models directory: {models_dir}\")\n",
    "print(f\"   Models saved: {saved_models}\")\n",
    "print(f\"   Encoders saved: {len(encoders)}\")\n",
    "print(f\"     Feature columns: {len(feature_columns)}\")\n",
    "\n",
    "# List saved files\n",
    "print(f\"\\nSaved Files:\")\n",
    "for file in os.listdir(models_dir):\n",
    "    if file.endswith('.pkl'):\n",
    "        filepath = os.path.join(models_dir, file)\n",
    "        size_kb = os.path.getsize(filepath) / 1024\n",
    "        print(f\"   {file} ({size_kb:.1f} KB)\")\n",
    "\n",
    "# Display metadata\n",
    "print(f\"\\nModel Metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    if key == 'accuracy_scores':\n",
    "        print(f\"   {key}: {value}\")\n",
    "    elif key == 'feature_columns':\n",
    "        print(f\"   {key}: {len(value)} features\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc78be",
   "metadata": {},
   "source": [
    "## 9. Load Models and Make Predictions\n",
    "\n",
    "Demonstrate loading the saved models and making predictions for sample user profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_models():\n",
    "    \"\"\"Load all saved models, encoders, and scalers\"\"\"\n",
    "    \n",
    "    print(\"Loading saved models...\")\n",
    "    \n",
    "    # Load models\n",
    "    loaded_models = {}\n",
    "    model_files = {\n",
    "        'next_job': 'svm_next_job_model.pkl',\n",
    "        'next_institution': 'svm_next_institution_model.pkl',\n",
    "        'career_transition': 'svm_career_transition_model.pkl',\n",
    "        'salary_range': 'svm_salary_range_model.pkl'\n",
    "    }\n",
    "    \n",
    "    for model_name, filename in model_files.items():\n",
    "        filepath = os.path.join(models_dir, filename)\n",
    "        try:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                loaded_models[model_name] = pickle.load(f)\n",
    "            print(f\"   Loaded {model_name} model\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"   ERROR: Model file not found: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ERROR loading {model_name}: {e}\")\n",
    "    \n",
    "    # Load encoders\n",
    "    try:\n",
    "        with open(os.path.join(models_dir, 'svm_encoders.pkl'), 'rb') as f:\n",
    "            loaded_encoders = pickle.load(f)\n",
    "        print(f\"   Loaded encoders ({len(loaded_encoders)} encoders)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR loading encoders: {e}\")\n",
    "        loaded_encoders = {}\n",
    "    \n",
    "    # Load scalers\n",
    "    try:\n",
    "        with open(os.path.join(models_dir, 'svm_scalers.pkl'), 'rb') as f:\n",
    "            loaded_scalers = pickle.load(f)\n",
    "        print(f\"   Loaded scalers\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR loading scalers: {e}\")\n",
    "        loaded_scalers = {}\n",
    "    \n",
    "    # Load metadata\n",
    "    try:\n",
    "        with open(os.path.join(models_dir, 'svm_metadata.pkl'), 'rb') as f:\n",
    "            loaded_metadata = pickle.load(f)\n",
    "        print(f\"   Loaded metadata\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR loading metadata: {e}\")\n",
    "        loaded_metadata = {}\n",
    "    \n",
    "    return loaded_models, loaded_encoders, loaded_scalers, loaded_metadata\n",
    "\n",
    "def prepare_user_features(user_profile: Dict[str, Any], encoders: Dict, scaler, feature_columns: List[str]) -> np.ndarray:\n",
    "    \"\"\"Prepare user profile features for prediction\"\"\"\n",
    "    \n",
    "    feature_values = []\n",
    "    \n",
    "    for col in feature_columns:\n",
    "        if col in ['current_marks_value', 'tenth_percentage', 'twelfth_percentage']:\n",
    "            # Numerical features\n",
    "            value = float(user_profile.get(col, 70.0))\n",
    "            feature_values.append(value)\n",
    "        else:\n",
    "            # Categorical features\n",
    "            value = str(user_profile.get(col, 'Unknown'))\n",
    "            \n",
    "            if col in encoders:\n",
    "                try:\n",
    "                    encoded = encoders[col].transform([value])[0]\n",
    "                except ValueError:\n",
    "                    # Handle unseen categories\n",
    "                    encoded = 0  # Default to first category\n",
    "                feature_values.append(encoded)\n",
    "            else:\n",
    "                feature_values.append(0)\n",
    "    \n",
    "    # Create feature array and scale\n",
    "    features = np.array(feature_values).reshape(1, -1)\n",
    "    if 'main' in scaler:\n",
    "        features = scaler['main'].transform(features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def make_career_predictions(user_profile: Dict[str, Any], models: Dict, encoders: Dict, scaler: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"Make career predictions for a user profile\"\"\"\n",
    "    \n",
    "    # Prepare features\n",
    "    user_features = prepare_user_features(user_profile, encoders, scaler, feature_columns)\n",
    "    \n",
    "    predictions = {}\n",
    "    confidences = {}\n",
    "    \n",
    "    # Make predictions for each target\n",
    "    for target_name, model in models.items():\n",
    "        try:\n",
    "            # Get prediction\n",
    "            pred = model.predict(user_features)[0]\n",
    "            proba = model.predict_proba(user_features)[0]\n",
    "            \n",
    "            # Decode prediction\n",
    "            if target_name in encoders:\n",
    "                decoded_pred = encoders[target_name].inverse_transform([pred])[0]\n",
    "                predictions[target_name] = decoded_pred\n",
    "                confidences[target_name] = float(max(proba))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   WARNING: Error predicting {target_name}: {e}\")\n",
    "            predictions[target_name] = \"Unknown\"\n",
    "            confidences[target_name] = 0.0\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'user_profile': user_profile\n",
    "    }\n",
    "\n",
    "# Load saved models\n",
    "loaded_models, loaded_encoders, loaded_scalers, loaded_metadata = load_saved_models()\n",
    "\n",
    "# Test with sample user profiles\n",
    "test_profiles = [\n",
    "    {\n",
    "        'education_level': 'Undergraduate',\n",
    "        'current_course': 'B.Tech Computer Science',\n",
    "        'current_marks_value': 8.5,\n",
    "        'current_marks_type': 'CGPA',\n",
    "        'tenth_percentage': 88.5,\n",
    "        'twelfth_percentage': 91.2,\n",
    "        'place_of_residence': 'Mumbai',\n",
    "        'residence_type': 'Metro',\n",
    "        'family_background': 'Middle Income',\n",
    "        'interests': 'Coding|AI|Gaming',\n",
    "        'skills': 'Python|Web Development',\n",
    "        'career_goals': 'Software Engineering'\n",
    "    },\n",
    "    {\n",
    "        'education_level': 'Postgraduate',\n",
    "        'current_course': 'MBA Finance',\n",
    "        'current_marks_value': 8.2,\n",
    "        'current_marks_type': 'CGPA',\n",
    "        'tenth_percentage': 90.0,\n",
    "        'twelfth_percentage': 93.0,\n",
    "        'place_of_residence': 'Delhi',\n",
    "        'residence_type': 'Metro',\n",
    "        'family_background': 'Upper Income',\n",
    "        'interests': 'Finance|Business|Analytics',\n",
    "        'skills': 'Excel|Financial Modeling',\n",
    "        'career_goals': 'Investment Banking'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\nTesting Predictions with Sample Profiles:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, profile in enumerate(test_profiles, 1):\n",
    "    print(f\"\\nTest Profile {i}:\")\n",
    "    print(f\"   Education: {profile['education_level']} - {profile['current_course']}\")\n",
    "    print(f\"   Performance: {profile['current_marks_value']} {profile['current_marks_type']}\")\n",
    "    print(f\"   Interests: {profile['interests']}\")\n",
    "    print(f\"   Goal: {profile['career_goals']}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    result = make_career_predictions(profile, loaded_models, loaded_encoders, loaded_scalers)\n",
    "    \n",
    "    print(f\"\\nPredictions:\")\n",
    "    for pred_type, prediction in result['predictions'].items():\n",
    "        confidence = result['confidences'][pred_type]\n",
    "        print(f\"   {pred_type.replace('_', ' ').title()}: {prediction} (confidence: {confidence:.2f})\")\n",
    "\n",
    "print(f\"\\nModel testing completed successfully!\")\n",
    "print(f\"SVM models are ready for use in the CareerBuddy application!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b502ee",
   "metadata": {},
   "source": [
    "## Training Complete!\n",
    "\n",
    "### Summary\n",
    "\n",
    "This notebook successfully demonstrates the complete SVM model training pipeline for the CareerBuddy platform:\n",
    "\n",
    "1. **Data Loading**: Loaded career training data from CSV files\n",
    "2. **Preprocessing**: Cleaned and standardized data according to the CareerBuddy schema\n",
    "3. **Feature Engineering**: Encoded categorical features and scaled numerical features\n",
    "4. **Model Training**: Trained separate SVM models for:\n",
    "   - Next Job Prediction\n",
    "   - Institution Type Prediction  \n",
    "   - Career Transition Prediction\n",
    "   - Salary Range Prediction\n",
    "5. **Evaluation**: Assessed model performance with accuracy metrics and visualizations\n",
    "6. **Persistence**: Saved all models, encoders, and scalers for production use\n",
    "7. **Testing**: Demonstrated loading models and making predictions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Integration**: The saved models can now be used by the `SVMCareerPredictor` class in `backend/app/logic/svm_predictor.py`\n",
    "2. **API Usage**: Use the `/recommend/v2/svm/predict` endpoint to get predictions\n",
    "3. **Model Updates**: Retrain models periodically with new data using `/recommend/v2/svm/train`\n",
    "4. **Monitoring**: Track prediction accuracy and user feedback for continuous improvement\n",
    "\n",
    "### Model Files Created\n",
    "\n",
    "The following files are now available in `backend/models/`:\n",
    "- `svm_next_job_model.pkl` - Next job prediction model\n",
    "- `svm_next_institution_model.pkl` - Institution type prediction model  \n",
    "- `svm_career_transition_model.pkl` - Career transition prediction model\n",
    "- `svm_salary_range_model.pkl` - Salary range prediction model\n",
    "- `svm_encoders.pkl` - Label encoders for categorical features\n",
    "- `svm_scalers.pkl` - StandardScaler for feature normalization\n",
    "- `svm_metadata.pkl` - Model training metadata and configuration\n",
    "\n",
    "**Your SVM-powered career prediction system is now ready for production!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
